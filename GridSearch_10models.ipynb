{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 10-fold cross varidation\n",
    "# Divide the data into 10 parts and create 10 data sets with train-test=9:1\n",
    "# Perform a grid search for each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "df = pd.read_table('dataset.txt')\n",
    "# Check the imported data, display the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data arrangement\n",
    "data_x = df.drop(['species'], axis=1)\n",
    "data_y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into 10 parts and create 10 data sets with train-test=9:1\n",
    "# Export the CSV files (train_01.csv, test_01.csv ~)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits = 10, random_state=123, shuffle=True)\n",
    "ranges = range(1,11)\n",
    "for i, (train_idx, test_idx) in zip(ranges,(kfold.split(data_x, data_y))):\n",
    "    X_train = data_x.iloc[train_idx, :]\n",
    "    X_test = data_x.iloc[test_idx, :]\n",
    "    y_train = data_y.iloc[train_idx]\n",
    "    y_test = data_y.iloc[test_idx]\n",
    "    train_concat = pd.concat([y_train, X_train],axis=1)\n",
    "    test_concat = pd.concat([y_test, X_test],axis=1)\n",
    "    train_concat.to_csv(\"train_\"+\"%02.f\"%(i)+\".csv\", index=False)\n",
    "    test_concat.to_csv(\"test_\"+\"%02.f\"%(i)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the created data, display the first 5 rows\n",
    "xx=pd.read_csv(\"test_01.csv\")\n",
    "xx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model construction for grid search\n",
    "clf_cv = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for search _1st\n",
    "# Please change the number in [] you want to search\n",
    "search_params = {\n",
    "     'n_estimators'      : [10, 100, 200, 300, 500, 700, 1000, 1500],\n",
    "      'max_features'      : [\"sqrt\", 20, 30, 40, 50, 60, 70],\n",
    "      'random_state'      : [123],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search setting\n",
    "gs = GridSearchCV(clf_cv,          # model\n",
    "                  search_params,   # search parameters\n",
    "                  cv=5,            # cross validation\n",
    "                  verbose=True,    # display log \n",
    "                  n_jobs=-1)       # Number of parallel processing CPU cores. -1: using all processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a grid search for each data set\n",
    "ranges = range(1,11)\n",
    "for i in ranges:\n",
    "    train = pd.read_csv(\"train_\"+\"%02.f\"%(i)+\".csv\")\n",
    "    train_x = train.drop(['species', 'waves'], axis=1)\n",
    "    train_y = train['species']\n",
    "    gs.fit(train_x, train_y) \n",
    "    print(gs.best_estimator_) # print the result. checke 'n_estimators' and 'max_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for search _2st\n",
    "# If you can't decide in the 1st step, narrow down or change the number of parameters and search again\n",
    "search_params = {\n",
    "     'n_estimators'      : [200,300,400,500,600],\n",
    "      'max_features'      : [\"sqrt\"],\n",
    "      'random_state'      : [123],\n",
    "      'n_jobs'            : [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search setting_2nd\n",
    "gs = GridSearchCV(clf_cv, \n",
    "                  search_params,   \n",
    "                  cv=5,            \n",
    "                  verbose=True,    \n",
    "                  n_jobs=-1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a grid search for each data set_2nd\n",
    "for i in ranges:\n",
    "    train = pd.read_csv(\"train_\"+\"%02.f\"%(i)+\".csv\")\n",
    "    train_x = train.drop(['species', 'waves'], axis=1)\n",
    "    train_y = train['species']\n",
    "    gs.fit(train_x, train_y) \n",
    "    print(gs.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
