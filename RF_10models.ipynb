{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models using the parameters selected by grid search\n",
    "# Export feature importance, confusion matrix array and class probability for each train-test set\n",
    "# Calculate the score for each set\n",
    "# Visualize confusion matrix\n",
    "# OPTION: OOB error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "# Set the parameters selected by grid search\n",
    "clf = RandomForestClassifier(max_features='sqrt', n_estimators=200, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the feature importance as CSV file for each set\n",
    "# Export the confusion matrix array as numpy array for each set\n",
    "# Export the class probability as CSV file for each set\n",
    "# Calculate the accuracy score for each set\n",
    "ranges = range(1,11)\n",
    "score_all=['']*11\n",
    "for i in ranges:\n",
    "    train = pd.read_csv(\"train_\"+\"%02.f\"%(i)+\".csv\")\n",
    "    train_x = train.drop(['species','waves'], axis=1)\n",
    "    train_y = train['species']\n",
    "    test = pd.read_csv(\"test_\"+\"%02.f\"%(i)+\".csv\")\n",
    "    test_x = test.drop(['species','waves'], axis=1)\n",
    "    test_y = test['species']\n",
    "    test_w = test['waves']\n",
    "    clf.fit(train_x, train_y)\n",
    "    # feature importances export\n",
    "    FN =list(train_x.columns)\n",
    "    IF = list(zip(clf.feature_importances_,FN))\n",
    "    impFeat = pd.DataFrame(IF,columns=[\"Importance\",\"Feature_Name\"])\n",
    "    impFeat.to_csv(\"IF_\"+\"%02.f\"%(i)+\".csv\")\n",
    "    # for confusion matrix, make array\n",
    "    y_pred = clf.predict(test_x)\n",
    "    conf_mat = confusion_matrix(test_y, y_pred, \n",
    "                                labels=['Escherichia', 'Bacillus', 'Thermus', 'Thermococcus', 'Sulfolobus', 'Nitrososphaera']) \n",
    "                                # Sorting Classes. Sort in the specified order.\n",
    "    np.save(\"model_array_\"+\"%02.f\"%(i), conf_mat)\n",
    "    # class probability export\n",
    "    classproba = pd.DataFrame(clf.predict_proba(test_x), columns=clf.classes_)\n",
    "    classproba = pd.concat([test_w, test_y, classproba],axis=1)\n",
    "    classproba.to_csv(\"predict_proba_\"+\"%02.f\"%(i)+\".csv\")\n",
    "    # for score\n",
    "    score_all[i] = clf.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the score for each set\n",
    "score_all.pop(0) \n",
    "print(score_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the mean of scores\n",
    "print(np.mean(score_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the standard deviation of scores\n",
    "print(np.std(score_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the array\n",
    "# The order of the classes will be in the order in which you sorted them earlier\n",
    "print(np.load('model_array_01.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the arrays\n",
    "model_array_01 = np.load('model_array_01.npy')\n",
    "model_array_02 = np.load('model_array_02.npy')\n",
    "model_array_03 = np.load('model_array_03.npy')\n",
    "model_array_04 = np.load('model_array_04.npy')\n",
    "model_array_05 = np.load('model_array_05.npy')\n",
    "model_array_06 = np.load('model_array_06.npy')\n",
    "model_array_07 = np.load('model_array_07.npy')\n",
    "model_array_08 = np.load('model_array_08.npy')\n",
    "model_array_09 = np.load('model_array_09.npy')\n",
    "model_array_10 = np.load('model_array_10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition\n",
    "model_array_sum = model_array_01 + model_array_02 + model_array_03 + model_array_04 + model_array_05 + model_array_06 + model_array_07 + model_array_08 + model_array_09 + model_array_10\n",
    "model_array_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting for visualization of the confusion matrix\n",
    "# Display the number of samples: normalize=False\n",
    "# For percentages: normalize=True\n",
    "# Original script: https://scikit-learn.org/0.18/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import numpy as np\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the confusion matrix\n",
    "# !!CAUTION!! The order of the labels to be included in the 'species' should be the same order as the 'labels' above (line 5).\n",
    "species=['Escherichia', 'Bacillus', 'Thermus', 'Thermococcus', 'Sulfolobus', 'Nitrososphaera']\n",
    "plot_confusion_matrix(model_array_sum, species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize OOB error rate\n",
    "# !!CAUTION!! This script is heavy running; \n",
    "#  it is not recommended to use the 'for' syntax to calculate 10 sets once.\n",
    "\n",
    "# Author: Kian Ho <hui.kian.ho@gmail.com>\n",
    "#         Gilles Louppe <g.louppe@gmail.com>\n",
    "#         Andreas Mueller <amueller@ais.uni-bonn.de>\n",
    "#\n",
    "# License: BSD 3 Clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RANDOM_STATE = 123\n",
    "\n",
    "# Generate a binary classification dataset.\n",
    "#X, y = make_classification(\n",
    "    #n_samples=500,\n",
    "    #n_features=25,\n",
    "    #n_clusters_per_class=1,\n",
    "    #n_informative=15,\n",
    "    #random_state=RANDOM_STATE,\n",
    "#)\n",
    "\n",
    "# Because of the computation time required, \n",
    "# it is recommended to perform the calculation steadily, \n",
    "# one set at a time, without \"for\".\n",
    "train = pd.read_csv(\"train_01.csv\")\n",
    "X = train.drop(['species','waves'], axis=1)\n",
    "y = train['species']\n",
    "\n",
    "# NOTE: Setting the `warm_start` construction parameter to `True` disables\n",
    "# support for parallelized ensembles but is necessary for tracking the OOB\n",
    "# error trajectory during training.\n",
    "\n",
    "ensemble_clfs = [\n",
    "    (\n",
    "        \"RandomForestClassifier, max_features='sqrt'\",\n",
    "        RandomForestClassifier(\n",
    "            warm_start=True,\n",
    "            oob_score=True,\n",
    "            max_features=\"sqrt\",\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"RandomForestClassifier, max_features='log2'\",\n",
    "        RandomForestClassifier(\n",
    "            warm_start=True,\n",
    "            max_features=\"log2\",\n",
    "            oob_score=True,\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"RandomForestClassifier, max_features=None\",\n",
    "        RandomForestClassifier(\n",
    "            warm_start=True,\n",
    "            max_features=None,\n",
    "            oob_score=True,\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.\n",
    "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "\n",
    "# Range of `n_estimators` values to explore.\n",
    "min_estimators = 1\n",
    "max_estimators = 500\n",
    "\n",
    "for label, clf in ensemble_clfs:\n",
    "    for i in range(min_estimators, max_estimators + 1, 5):\n",
    "        clf.set_params(n_estimators=i)\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        # Record the OOB error for each `n_estimators=i` setting.\n",
    "        oob_error = 1 - clf.oob_score_\n",
    "        error_rate[label].append((i, oob_error))\n",
    "\n",
    "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "for label, clf_err in error_rate.items():\n",
    "    xs, ys = zip(*clf_err)\n",
    "    plt.plot(xs, ys, label=label)\n",
    "\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the oob error rate as numerical data\n",
    "# !!CAUTION!! This script is heavy running; \n",
    "#  it is not recommended to use the 'for' syntax to calculate 10 sets once.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RANDOM_STATE = 123\n",
    "\n",
    "train = pd.read_csv(\"train_01.csv\")\n",
    "X = train.drop(['species','waves'], axis=1)\n",
    "y = train['species']\n",
    "\n",
    "ensemble_clfs = [ \n",
    "   (\"RandomForestClassifier, max_features=sqrt\", \n",
    "       RandomForestClassifier(warm_start=True, oob_score=True, \n",
    "                              max_features='sqrt', \n",
    "                              random_state=RANDOM_STATE)), \n",
    "] \n",
    "\n",
    "# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs. \n",
    "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs) \n",
    "\n",
    "# Range of `n_estimators` values to explore. \n",
    "min_estimators = 1 \n",
    "max_estimators = 500\n",
    "number=[]\n",
    "for label, clfs in ensemble_clfs: \n",
    "    for i in range(min_estimators, max_estimators + 1): \n",
    "        clfs.set_params(n_estimators=i) \n",
    "        clfs.fit(X, y) \n",
    "\n",
    "        # Record the OOB error for each `n_estimators=i` setting. \n",
    "        oob_error = 1 - clfs.oob_score_ \n",
    "        error_rate[label].append(oob_error)\n",
    "        a = i\n",
    "        number.append(a)\n",
    "error_rate = pd.DataFrame(error_rate)\n",
    "number = pd.DataFrame(number)\n",
    "error_rate = pd.concat([number, error_rate],axis=1)\n",
    "error_rate = error_rate.rename(columns = {0: 'No of Tree'})\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "error_rate.to_csv(\"error_rate_01.csv\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
