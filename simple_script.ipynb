{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('sampledataset_rep1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df.drop(['species', 'waves'], axis=1) \n",
    "train_y = df['species'] \n",
    "(train_x, test_x ,train_y, test_y) = train_test_split(train_x, train_y, test_size = 0.2, stratify=train_y, random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model for grid search\n",
    "clf_cv = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for search _1st\n",
    "search_params = {\n",
    "     'n_estimators'      : [10, 100, 200, 300, 500, 700, 1000, 1500],\n",
    "      'max_features'      : [\"sqrt\", 20, 30, 40, 50, 60, 70],\n",
    "      'random_state'      : [123],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search setting\n",
    "gs = GridSearchCV(clf_cv,          # model\n",
    "                  search_params,   # search parameters\n",
    "                  cv=5,            # closs validation\n",
    "                  verbose=True,    # display log \n",
    "                  n_jobs=-1)       # Number of parallel processing CPU cores. -1: using all processors\n",
    "gs.fit(train_x, train_y) \n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "# Set the parameters selected by grid search\n",
    "clf = RandomForestClassifier(max_features='sqrt', n_estimators=500, oob_score=True, random_state=123) \n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcurate score\n",
    "score = clf.score(test_x, test_y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances export\n",
    "FN =list(train_x.columns)\n",
    "IF = list(zip(clf.feature_importances_,FN))\n",
    "impFeat = pd.DataFrame(IF,columns=[\"Importance\",\"Feature_Name\"])\n",
    "impFeat.to_csv(\"IF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class probability export\n",
    "classproba = pd.DataFrame(clf.predict_proba(test_x), columns=clf.classes_)\n",
    "classproba = pd.concat([test_y.reset_index(drop=True), classproba],axis=1)\n",
    "classproba.to_csv(\"predict_proba.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For confusion matrix\n",
    "y_pred = clf.predict(test_x)\n",
    "conf_mat = confusion_matrix(test_y, y_pred, labels=['Escherichia', 'Bacillus', 'Thermus', 'Thermococcus', 'Sulfolobus', 'Nitrososphaera']) # Sorting Classes. Sort in the specified order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting for visualization of the confusion matrix\n",
    "## Display the number of samples: normalize=False\n",
    "## For percentages: normalize=True\n",
    "# Original script: https://scikit-learn.org/0.18/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import numpy as np\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the confusion matrix\n",
    "# !!CAUTION!! The order of the labels to be included in the 'species' should be the same order as the 'labels' above (line 5).\n",
    "species=['Escherichia', 'Bacillus', 'Thermus', 'Thermococcus', 'Sulfolobus', 'Nitrososphaera']\n",
    "plot_confusion_matrix(conf_mat, species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize OOB error rate\n",
    "\n",
    "# Author: Kian Ho <hui.kian.ho@gmail.com>\n",
    "#         Gilles Louppe <g.louppe@gmail.com>\n",
    "#         Andreas Mueller <amueller@ais.uni-bonn.de>\n",
    "#\n",
    "# License: BSD 3 Clause\n",
    "\n",
    "# Original script: https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RANDOM_STATE = 123\n",
    "\n",
    "# Generate a binary classification dataset.\n",
    "#X, y = make_classification(\n",
    "    #n_samples=500,\n",
    "    #n_features=25,\n",
    "    #n_clusters_per_class=1,\n",
    "    #n_informative=15,\n",
    "    #random_state=RANDOM_STATE,\n",
    "#)\n",
    "\n",
    "X = df.drop(['species', 'waves'], axis=1) \n",
    "y = df['species'] \n",
    "\n",
    "# NOTE: Setting the `warm_start` construction parameter to `True` disables\n",
    "# support for parallelized ensembles but is necessary for tracking the OOB\n",
    "# error trajectory during training.\n",
    "\n",
    "ensemble_clfs = [\n",
    "    (\n",
    "        \"RandomForestClassifier, max_features='sqrt'\",\n",
    "        RandomForestClassifier(\n",
    "            warm_start=True,\n",
    "            oob_score=True,\n",
    "            max_features=\"sqrt\",\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"RandomForestClassifier, max_features='log2'\",\n",
    "        RandomForestClassifier(\n",
    "            warm_start=True,\n",
    "            max_features=\"log2\",\n",
    "            oob_score=True,\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"RandomForestClassifier, max_features=None\",\n",
    "        RandomForestClassifier(\n",
    "            warm_start=True,\n",
    "            max_features=None,\n",
    "            oob_score=True,\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.\n",
    "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "\n",
    "# Range of `n_estimators` values to explore.\n",
    "min_estimators = 1\n",
    "max_estimators = 500\n",
    "\n",
    "for label, clf in ensemble_clfs:\n",
    "    for i in range(min_estimators, max_estimators + 1, 5):\n",
    "        clf.set_params(n_estimators=i)\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        # Record the OOB error for each `n_estimators=i` setting.\n",
    "        oob_error = 1 - clf.oob_score_\n",
    "        error_rate[label].append((i, oob_error))\n",
    "\n",
    "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "for label, clf_err in error_rate.items():\n",
    "    xs, ys = zip(*clf_err)\n",
    "    plt.plot(xs, ys, label=label)\n",
    "\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the oob error rate as numerical data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RANDOM_STATE = 123\n",
    "\n",
    "X = df.drop(['species', 'waves'], axis=1) \n",
    "y = df['species']\n",
    "\n",
    "ensemble_clfs = [ \n",
    "   (\"RandomForestClassifier, max_features=sqrt\", \n",
    "       RandomForestClassifier(warm_start=True, oob_score=True, \n",
    "                              max_features='sqrt', \n",
    "                              random_state=RANDOM_STATE)), \n",
    "] \n",
    "\n",
    "# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs. \n",
    "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs) \n",
    "\n",
    "# Range of `n_estimators` values to explore. \n",
    "min_estimators = 1 \n",
    "max_estimators = 500\n",
    "number=[]\n",
    "for label, clfs in ensemble_clfs: \n",
    "    for i in range(min_estimators, max_estimators + 1): \n",
    "        clfs.set_params(n_estimators=i) \n",
    "        clfs.fit(X, y) \n",
    "\n",
    "        # Record the OOB error for each `n_estimators=i` setting. \n",
    "        oob_error = 1 - clfs.oob_score_ \n",
    "        error_rate[label].append(oob_error)\n",
    "        a = i\n",
    "        number.append(a)\n",
    "error_rate = pd.DataFrame(error_rate)\n",
    "number = pd.DataFrame(number)\n",
    "error_rate = pd.concat([number, error_rate],axis=1)\n",
    "error_rate = error_rate.rename(columns = {0: 'No of Tree'})\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "error_rate.to_csv(\"error_rate.csv\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
